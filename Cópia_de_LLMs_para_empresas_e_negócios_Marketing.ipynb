{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vassoleri/LLMs-for-marketing-business/blob/main/C%C3%B3pia_de_LLMs_para_empresas_e_neg%C3%B3cios_Marketing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EasSpF1MeP9y"
      },
      "source": [
        "# Projeto para Departamento de Marketing\n",
        "\n",
        "Nosso objetivo com esse projeto é criar um assistente de geração de conteúdo automatizado, que adapta o texto ao público e ao canal de divulgação. Confira os slides para mais detalhes sobre a proposta desse estudo de caso.\n",
        "\n",
        "\n",
        "> **Importante:** Caso dê algum erro no processo de instalação e que impeça de prosseguir com a execução do código, confira o Colab da aula e verifique se fez uma cópia do mais atualizado, pois atualizaremos essas etapas de instalação com os comandos atualizados (caso seja necessária alguma mudança no comando de instalação).\n",
        "\n",
        "Vamos usar primeiro o ipynb no Colab para desenvolver e validar a lógica com LLMs, onde aprenderemos a deixar uma aplicação funcional dentro do próprio Colab usando ipywidgets. Ao final, veremos como adaptar isso para uma interface profissional usando o framework Streamlit, pronto para publicar. Isso evita retrabalho, ajuda a testar ideias com rapidez e foca primeiro no que importa: o núcleo funcional, a lógica e conceitos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHosOe1ZRuQl"
      },
      "source": [
        "## Instalação das bibliotecas\n",
        "\n",
        "Abaixo instalaremos algumas bibliotecas essenciais para o desenvolvimento de nosso projeto.\n",
        "\n",
        "Para instalação usaremos o comando pip install. Passaremos o parâmetro -q (quiet) para reduzir a verbosidade da saída no terminal, exibindo apenas erros e mensagens essenciais. É usado para simplificar a visualização durante instalações automatizadas ou em ambientes onde logs detalhados não são necessários.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsbPf_jusAEn",
        "outputId": "49d1d674-544f-43d9-be74-14e302b396fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q \"requests==2.32.4\" langchain-community langchain-groq ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Za79_C2GYe9"
      },
      "source": [
        "### Importar bibliotecas  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcQ92GsQthem"
      },
      "outputs": [],
      "source": [
        "from google.colab import widgets\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT-DAEK-uU0b"
      },
      "source": [
        "# Criação dos campos - Interface\n",
        "\n",
        "Antes de partirmos para o código, é importante definirmos com clareza os campos que a aplicação irá utilizar. Essa etapa é essencial para evitar dispersão e garantir que o desenvolvimento seja focado nas necessidades reais da empresa.\n",
        "\n",
        "> Campos *(conforme discutido na apresentação do estudo de caso)*\n",
        " * Plataforma de destino (ex: Blog, Instagram, LinkedIn, E-mail)\n",
        " * Tom da mensagem (ex: Informativo, Inspirador, Urgente, Informal)\n",
        " * Comprimento do texto (ex: Curto, Médio, Longo)\n",
        " * Tema ou tópico (ex: alimentação, saúde mental, exames de rotina, cuidados, etc.)\n",
        " * Público-alvo (Jovens adultos, Famílias, Idosos, Geral, etc.)\n",
        " * Opções adicionais:\n",
        "  * Incluir chamada para ação (ex: “Agendar consulta” ou “Converse com um especialista”)\n",
        "  * Retornar hashtags\n",
        "  * Inserir palavras-chave para incluir no meio do texto\n",
        "\n",
        "\n",
        "Vamos começar criando um campo em formato de texto. O `widgets.Text` cria um campo livre para digitação, onde o usuário insere o conteúdo manualmente.\n",
        "\n",
        "* `description`: texto que aparece como rótulo do campo (ajuda a identificar sua função).\n",
        "* `placeholder`: texto que aparece dentro do campo antes do preenchimento, como sugestão ou exemplo. Vamos aproveitar para colocar uma sugestão já do que o usuário pode digitar, o que é uma boa prática de user experience (UX)\n",
        "\n",
        "Obs: Pensando nas boas práticas, também vamos aproveitar para definir os nomes das variáveis em inglês (tema vai ser *topic*, público-alvo vai ser *audience*, etc.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JY-IhmQvdSG"
      },
      "outputs": [],
      "source": [
        "topic = widgets.Text(\n",
        "    description = 'Tema:',\n",
        "    placeholder = 'Ex: saúde mental, alimentação saudável, prevenção, etc.'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdAL78Pf6kMb"
      },
      "source": [
        "### Exibindo o widget\n",
        "\n",
        "Para exibir os campos/widgets que criamos vamos usar o método display(). Com isso o campo vai aparecer dentro da saída do bloco de código abaixo, assim exibindo tudo de forma interativa dentro desse notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4341db4ded8443288d701b9be22c436f",
            "6a98d6322c6945e6bc341cbad9abb014",
            "1d1bcd9dd7224bccbe574f134f90bb72"
          ]
        },
        "id": "HGbVHL6IvuGp",
        "outputId": "1d88d4dd-147f-4135-b9f3-7bc07180584d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Tema:', placeholder='Ex: saúde mental, alimentação saudável, prevenção, etc.')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4341db4ded8443288d701b9be22c436f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "collapsed": true,
        "id": "XyGoOfkov3lo",
        "outputId": "efb0c6f3-2368-456c-99e4-662418214c20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "topic.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3-f1FUAhF3i"
      },
      "source": [
        "### Ajustando propriedades do campo\n",
        "\n",
        "Por padrão, o widget Text do ipywidgets cria um campo de entrada relativamente estreito, o que pode não ser ideal quando esperamos que o usuário digite frases ou trechos mais longos.\n",
        "\n",
        "Com `layout=widgets.Layout(width='500px')` definimos explicitamente a largura do campo como 500 pixels, o que é mais apropriado quando esperamos frases completas.\n",
        "\n",
        "* Você pode ajustar esse valor conforme a necessidade - ex: '100%' para ocupar toda a largura do container (deixando responsivo), ou '700px' para um campo ainda maior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "35e36a5f82874bfcbad64d900666e321",
            "f0304498b77c4e9eb71516cb328f4bf6",
            "129c8443633b49fd94e7913c9734ada4"
          ]
        },
        "id": "RsS7PXiYwDxO",
        "outputId": "996a9e7d-c4d5-47ad-9ff5-e553f20115bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Tema:', layout=Layout(width='500px'), placeholder='Ex: saúde mental, alimentação s…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e36a5f82874bfcbad64d900666e321"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "topic = widgets.Text(\n",
        "    description = 'Tema:',\n",
        "    placeholder = 'Ex: saúde mental, alimentação saudável, prevenção, etc.',\n",
        "    layout = widgets.Layout(width='500px')\n",
        ")\n",
        "display(topic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW9MreKJwij2"
      },
      "source": [
        "### Outros formatos de campos\n",
        "\n",
        "Para adicionar campos de seleção práticos e dinâmicos à nossa aplicação, utilizaremos a função widgets.Dropdown, que exibe opções em formato de lista suspensa. Passaremos as escolhas disponíveis através do parâmetro options e, para otimizar a interface e facilitar futuras alterações, definiremos uma largura padrão para esses campos usando uma variável, permitindo ajustes globais de tamanho de forma simples, o que pode ser muito útil caso os valores pré-definidos sejam extensos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "e2bdab56ce824ca9b908fae804ab7425",
            "0299e82c52304d8ca88cf41c50d4eed5",
            "e3c621de95624683a77b4c80f86212e6",
            "b69ba16998b24b95943171e9e07dbee2",
            "0a9c2ec91404485db7a7b0a812e11b16",
            "0ee1ecf9e84d4eb2b6da834c753feaa8",
            "9c8890cd00a44c29987fb02bfade45f8",
            "23b14597e67b4af3a89f56afd424565d",
            "34fff4152d54492c974ba0e3117e792e",
            "0fb2156884344740a342a0a51f91787a",
            "271de9033b78475cb8bbfded02cac237",
            "cc1d9c4773e44f3b92649b8d5d256c0d"
          ]
        },
        "id": "svF7IUPWwz7I",
        "outputId": "77454aab-9ce8-4298-e226-ca5cad9e372f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Plataforma', layout=Layout(width='250px'), options=('Instagram', 'Facebook', 'LinkedIn',…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2bdab56ce824ca9b908fae804ab7425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Tom:', layout=Layout(width='250px'), options=('Normal', 'Informativo', 'Inspirador', 'Ur…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b69ba16998b24b95943171e9e07dbee2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Tamanho:', layout=Layout(width='250px'), options=('Curto', 'Médio', 'Longo'), value='Cur…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c8890cd00a44c29987fb02bfade45f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Público-alvo:', layout=Layout(width='250px'), options=('Geral', 'Jovens adultos', 'Famíl…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb2156884344740a342a0a51f91787a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "w_dropdown = '250px'\n",
        "\n",
        "platform = widgets.Dropdown(\n",
        "    options = ['Instagram', 'Facebook', 'LinkedIn', 'Blog', 'E-mail'],\n",
        "    description = 'Plataforma',\n",
        "    layout = widgets.Layout(width = w_dropdown)\n",
        ")\n",
        "\n",
        "tone = widgets.Dropdown(\n",
        "    options=['Normal', 'Informativo', 'Inspirador', 'Urgente', 'Informal'],\n",
        "    description='Tom:',\n",
        "    layout=widgets.Layout(width=w_dropdown)\n",
        ")\n",
        "\n",
        "length = widgets.Dropdown(\n",
        "    options=['Curto', 'Médio', 'Longo'],\n",
        "    description='Tamanho:',\n",
        "    layout=widgets.Layout(width=w_dropdown)\n",
        ")\n",
        "\n",
        "audience = widgets.Dropdown(\n",
        "    options=['Geral', 'Jovens adultos', 'Famílias', 'Idosos', 'Adolescentes'],\n",
        "    description='Público-alvo:',\n",
        "    layout=widgets.Layout(width=w_dropdown)\n",
        ")\n",
        "\n",
        "\n",
        "display(platform, tone, length, audience)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hxfLLzB-xV1t",
        "outputId": "48eaa708-1e39-4b74-9c17-09c884c8fcda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Instagram'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "platform.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFVCCtjj0Fkt"
      },
      "source": [
        "Para incorporar opções de ativar/desativar funcionalidades, como incluir uma Chamada para Ação (CTA) ou solicitar sugestões de hashtags, utilizaremos widgets.Checkbox.\n",
        "\n",
        "Estes campos booleanos (Verdadeiro/Falso) serão configurados com um valor inicial (por padrão, desmarcado) e uma descrição clara de sua função, permitindo ao usuário controlar facilmente aspectos específicos da geração de conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLaJShGnxwEi"
      },
      "outputs": [],
      "source": [
        "cta = widgets.Checkbox(\n",
        "    value = False,\n",
        "    description = 'Incluir CTA'\n",
        ")\n",
        "\n",
        "hashtags = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Retornar Hashtags',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "300a1da0f87d4c20930b8236cb921313",
            "b1429d3fc8d249beb273cb64ecf2acf5",
            "5056d268d76d4d3499273dc378a50e0d"
          ]
        },
        "id": "EiuCgkZJyCzD",
        "outputId": "481589d1-d581-4a18-a309-165a6dcae23b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Checkbox(value=False, description='Incluir CTA')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "300a1da0f87d4c20930b8236cb921313"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(cta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzMGcUDdyFXS",
        "outputId": "f39f1fc5-1546-455f-9f5c-73aba8660f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cta.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWsiNQJ0SRU"
      },
      "source": [
        "Para permitir a inserção de textos mais longos, como listas de palavras-chave para SEO, implementaremos um campo do tipo Textarea. Este campo opcional dará ao usuário a flexibilidade de especificar termos que a IA deve incorporar naturalmente ao conteúdo, e seu tamanho pode ser ajustado em largura e altura para melhor acomodar o texto inserido, utilizando `widgets.Layout` para definir dimensões como height."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lYqrlA-yOuE"
      },
      "outputs": [],
      "source": [
        "keywords = widgets.Textarea(\n",
        "    description = 'Palavras-chave (SEO)',\n",
        "    placeholder = 'Ex: bem-estar, medicina preventiva...',\n",
        "    layout = widgets.Layout(width = '500px', height = '50px')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71,
          "referenced_widgets": [
            "a60140076ead460c8c0e0bc3311eeeba",
            "7aa393414c6948c5b164d2b9f09eb21c",
            "5f7751ccecc245789af2a84301bc3a21"
          ]
        },
        "id": "91bhwGlFyhuj",
        "outputId": "b5a1626a-bddf-4194-8ef1-13cfdfdce202"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', description='Palavras-chave (SEO)', layout=Layout(height='50px', width='500px'), placeholde…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a60140076ead460c8c0e0bc3311eeeba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn6dq0zh0Qav"
      },
      "source": [
        "## Criando o botão de geração\n",
        "\n",
        "Vamos agora adicionar um botão à interface. Esse botão será clicado para gerar o conteúdo com base nos campos preenchidos. O parâmetro description aqui é o texto que aparece no botão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "94212f66ad5748e09a47f257c4f54afc",
            "bb519a8ea337412a8eb4d5382266552a",
            "3e6f46a0afac4de8bf4419a0b0a0ddb6"
          ]
        },
        "id": "KrUDyyyD0BUZ",
        "outputId": "b9d3f554-eb1a-4938-848e-a9da82a569a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Gerar conteúdo', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94212f66ad5748e09a47f257c4f54afc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "generate_button = widgets.Button(\n",
        "    description = 'Gerar conteúdo',\n",
        ")\n",
        "\n",
        "display(generate_button)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOXdzu9M4WWB"
      },
      "source": [
        "## Exibição do resultado\n",
        "\n",
        "Precisamos criar um espaço para exibir o output, que é o resultado gerado pela LLM.\n",
        "\n",
        "Usamos o Output() para mostrar o resultado da geração de conteúdo. Ele cria uma “área de resposta”, onde vamos exibir o conteúdo gerado. Tudo que for mostrado com display() ou print() dentro dele aparecerá aqui.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlo0z66A0Tkl"
      },
      "outputs": [],
      "source": [
        "output = widgets.Output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqyeSdw0bK4"
      },
      "source": [
        "### Definindo ação do botão\n",
        "\n",
        "Por enquanto o botão não faz nada, precisamos criar uma função que será executada quando ele for clicado.\n",
        "\n",
        "Explicando os parâmetros:\n",
        "\n",
        "* `b` é o próprio botão sendo passado como argumento (padrão do on_click).\n",
        "\n",
        "* `with output`: garante que tudo dentro desse bloco apareça na área de saída.\n",
        "\n",
        "* `clear_output()` limpa o resultado anterior, evitando sobreposição de textos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE2kWaqZ0eAH"
      },
      "outputs": [],
      "source": [
        "def generate_result(b):\n",
        "  with output:\n",
        "    output.clear_output()\n",
        "    print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG23q18p0iCa"
      },
      "source": [
        "**Ligando o botão à função**\n",
        "\n",
        "`.on_click()` define que nossa função será executada quando o botão for pressionado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE5-H4DV0u1j"
      },
      "outputs": [],
      "source": [
        "generate_button.on_click(generate_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzlgFHpG0i6m"
      },
      "source": [
        "**Testando**\n",
        "\n",
        "Execute o bloco de código abaixo e clique no botão para verificar se nosso método está funcionando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "94212f66ad5748e09a47f257c4f54afc",
            "bb519a8ea337412a8eb4d5382266552a",
            "3e6f46a0afac4de8bf4419a0b0a0ddb6",
            "019ed3585d9346128b8830ab024d2949",
            "e9b2689633f04d478b50e8245be2c121"
          ]
        },
        "id": "m_Uvwg_A00TB",
        "outputId": "c6d97017-0516-497e-9286-54e771738132"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Gerar conteúdo', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94212f66ad5748e09a47f257c4f54afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019ed3585d9346128b8830ab024d2949"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(generate_button, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-XJQjMS2iJx"
      },
      "source": [
        "## Exibindo os campos juntos na interface\n",
        "\n",
        "Por fim, precisamos organizar os campos e exibi-los num layout final junto ao botão.\n",
        "Antes de chamarmos a função display (para exibir tudo de forma interativa dentro desse notebook) vamos usar a função `VBox()`, para organizar os elementos na vertical, na ordem em que forem listados.\n",
        "\n",
        "E para evitar a repetição, coloque dentro de uma função chamada \"create_form\", que retorne esse VBox com os widgets. Assim seu código fica mais limpo e reutilizável, pois usaremos mais tarde esses campos novamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "4ad8acbaf16b42359c56f0b9e65135db",
            "35e36a5f82874bfcbad64d900666e321",
            "e2bdab56ce824ca9b908fae804ab7425",
            "b69ba16998b24b95943171e9e07dbee2",
            "9c8890cd00a44c29987fb02bfade45f8",
            "0fb2156884344740a342a0a51f91787a",
            "300a1da0f87d4c20930b8236cb921313",
            "27ba1b96670c409eaed4d6e37b1263da",
            "a60140076ead460c8c0e0bc3311eeeba",
            "94212f66ad5748e09a47f257c4f54afc",
            "019ed3585d9346128b8830ab024d2949",
            "fe940e1f861342bfa398cc04d779b83a",
            "f0304498b77c4e9eb71516cb328f4bf6",
            "129c8443633b49fd94e7913c9734ada4",
            "0299e82c52304d8ca88cf41c50d4eed5",
            "e3c621de95624683a77b4c80f86212e6",
            "0a9c2ec91404485db7a7b0a812e11b16",
            "0ee1ecf9e84d4eb2b6da834c753feaa8",
            "23b14597e67b4af3a89f56afd424565d",
            "34fff4152d54492c974ba0e3117e792e",
            "271de9033b78475cb8bbfded02cac237",
            "cc1d9c4773e44f3b92649b8d5d256c0d",
            "b1429d3fc8d249beb273cb64ecf2acf5",
            "5056d268d76d4d3499273dc378a50e0d",
            "d39913c90fe04fca8d19bd4915b8db82",
            "ed24be2c4aec43f889017ec3aab86a50",
            "7aa393414c6948c5b164d2b9f09eb21c",
            "5f7751ccecc245789af2a84301bc3a21",
            "bb519a8ea337412a8eb4d5382266552a",
            "3e6f46a0afac4de8bf4419a0b0a0ddb6",
            "e9b2689633f04d478b50e8245be2c121"
          ]
        },
        "id": "rOBnn2rM1FIu",
        "outputId": "5db52925-27ca-4d4d-b9f0-5994bfb9086d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Tema:', layout=Layout(width='500px'), placeholder='Ex: saúde mental…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ad8acbaf16b42359c56f0b9e65135db"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_form():\n",
        "  return widgets.VBox([\n",
        "      topic,\n",
        "      platform,\n",
        "      tone,\n",
        "      length,\n",
        "      audience,\n",
        "      cta,\n",
        "      hashtags,\n",
        "      keywords,\n",
        "      generate_button,\n",
        "      output\n",
        "  ])\n",
        "\n",
        "form = create_form()\n",
        "\n",
        "display(form)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH3Ret-CEkdM"
      },
      "source": [
        "# Conectando com a LLM\n",
        "\n",
        "Para integrar a LLM à nossa aplicação, precisamos definir o modelo e a forma de implementação, que pode ser via download (para modelos open source, garantindo execução local e privacidade) ou através de API (simplificando a integração, oferecendo boa performance em qualquer máquina, mas com processamento de dados em servidores externos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVUysXq9JxV"
      },
      "source": [
        "## Escolhendo o modelo\n",
        "\n",
        "Na fase inicial de testes, recomenda-se começar com um modelo open source acessível via API gratuita, o que simplifica a implementação e reduz custos. Mesmo após a aplicação estar funcionando, esses modelos seguem vantajosos pela flexibilidade e economia. Neste curso, iniciaremos com o uso via API para evitar a complexidade da configuração local. Mais adiante, ensinaremos como rodar modelos localmente, permitindo que você compare as abordagens e escolha a mais adequada ao seu caso.\n",
        "\n",
        "Usaremos a biblioteca LangChain para integrar com a Groq, aproveitando seu módulo nativo de conexão e os benefícios que ela oferece no desenvolvimento.\n",
        "\n",
        "Para escolher bons modelos, recomendamos consultar leaderboards comparativos, como:\n",
        " * o https://lmarena.ai/?leaderboard\n",
        " * ou ranking específico para português na Hugging Face - https://huggingface.co/spaces/eduagarcia/open_pt_llm_leaderboard\n",
        "\n",
        "**Adicionando a key**\n",
        "\n",
        "Antes de começar com o código, você deve colar no campo a sua key gerada dentro do painel do Groq: https://console.groq.com/keys\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjTLin8eIAis",
        "outputId": "7f6e355d-6316-4627-cf4b-7df9fee4f282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV5uX4vt2Woh"
      },
      "source": [
        "Lembre-se que não precisamos pagar para usar modelos disponibilizados gratuitamente pelo provedor.\n",
        "\n",
        "* Essa próxima linha usa o método ChatGroq para configuração do modelo via API do Groq.\n",
        "\n",
        "* Escolhemos um modelo gratuito, dentro da aba *free tier* https://console.groq.com/docs/rate-limits. Copie o ID do modelo e adicione no campo a seguir\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQI2ddepH-ul"
      },
      "outputs": [],
      "source": [
        "id_model = \"llama-3.1-8b-instant\" #@param {type: \"string\"}\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model = id_model,\n",
        "    temperature = 0.7,\n",
        "    max_tokens=None,\n",
        "    timeout = None,\n",
        "    max_retries = 2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMV_dJey2wFi"
      },
      "source": [
        "### Explicações do método\n",
        "\n",
        "Para este teste definimos a temperatura como 0.7.\n",
        "A temperatura é um hiperparâmetro que ajusta a aleatoriedade da resposta da LLM.\n",
        "\n",
        "* Temperaturas mais altas (0.8-1.0) geram saídas mais criativas, ideais para brainstorming, enquanto temperaturas baixas (0.0-0.4) produzem respostas mais focadas e determinísticas, adequadas para tarefas técnicas;\n",
        "* valores médios (0.5-0.7) oferecem um equilíbrio, sendo um bom ponto de partida para geração de conteúdo geral, embora seja recomendável experimentar diferentes valores conforme o objetivo e o modelo.\n",
        "Além da temperatura, outros parâmetros como max_tokens (limite de tokens), timeout (tempo máximo de resposta) e max_retries (tentativas em caso de falha) podem ser configurados para otimizar o comportamento da LLM, com a documentação da LangChain para Groq oferecendo detalhes sobre todas as opções disponíveis.\n",
        "\n",
        "https://python.langchain.com/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqpIkQKKdKyu"
      },
      "source": [
        "### Formato das mensagens\n",
        "\n",
        "Ao interagir com a LLM, estruturamos o prompt como uma troca de mensagens, cada uma com uma função (ou *role*, como \"human\" para nossa entrada e \"system\" para instruções gerais que garantem consistência) e um conteúdo (a mensagem em si, seja texto ou dados estruturados).\n",
        "\n",
        "O prompt de sistema é crucial para definir o comportamento base da LLM, como atribuir um papel ou instruções padrão, e embora um prompt genérico possa funcionar, um prompt de sistema específico para a aplicação melhora significativamente a consistência dos resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fECsTInB3IXQ",
        "outputId": "967c0e92-3c03-4328-a38a-61a28c7c0662"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá! Eu sou um modelo de linguagem treinado para ser um redator profissional. Isso significa que estou capacitado para criar conteúdo de alta qualidade em uma variedade de formatos e estilos, desde artigos e textos de blog até resumos e relatórios.\\n\\nEu tenho conhecimento em uma ampla gama de tópicos e posso ajudar a criar conteúdo atraente e informacional para diferentes audiências. Além disso, posso ajudar a revisar e editar textos existentes para melhorar a clareza, a coerência e o estilo.\\n\\nSe você precisar de ajuda com algum projeto de escrita, estou aqui para ajudar! Qual é o seu objetivo? Quer criar um artigo, um texto de blog ou algo mais?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 51, 'total_tokens': 227, 'completion_time': 0.316580704, 'prompt_time': 0.002715755, 'queue_time': 0.053249425, 'total_time': 0.319296459}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a7a2f9abbf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5ad7427b-c532-471e-be42-66c393683d86-0', usage_metadata={'input_tokens': 51, 'output_tokens': 176, 'total_tokens': 227})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "prompt = \"Olá! Quem é você?\" # @param {type:\"string\"}\n",
        "\n",
        "template = [\n",
        "    (\"system\", \"Você é um redator profissional.\"),\n",
        "    (\"human\", prompt)\n",
        "]\n",
        "\n",
        "res = llm.invoke(template)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOrEl2QTIwY9",
        "outputId": "d18b32e6-1987-4169-b30d-fd9d2efe2451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Olá! Meu nome é [nome não fornecido], sou um redator profissional e estou aqui para ajudar a criar conteúdo de qualidade e atraente para você. Tenho experiência em escrever em vários gêneros, desde artigos e notícias até contos e histórias.\\n\\nMeu objetivo é fornecer informações precisas, interessantes e fáceis de entender. Estou sempre preparado para trabalhar em projetos novos e inovadores, e estou ansioso para ouvir suas ideias e contribuir para o seu sucesso.\\n\\nO que você gostaria de discutir? Quer que eu ajude a criar um texto, ou talvez você tenha uma ideia para um projeto que precise de uma mão extra? Estou aqui para ajudar!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 174, 'prompt_tokens': 51, 'total_tokens': 225, 'completion_time': 0.287279142, 'prompt_time': 0.002842366, 'queue_time': 0.048449314, 'total_time': 0.290121508}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_50a6be1b6f', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--b5820114-7a65-4579-9280-10accf67f738-0', usage_metadata={'input_tokens': 51, 'output_tokens': 174, 'total_tokens': 225})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "prompt = \"Olá! Quem é você?\" # @param {type:\"string\"}\n",
        "\n",
        "template = [\n",
        "    (\"system\", \"Você é um redator profissional.\"),\n",
        "    (\"human\", prompt)\n",
        "]\n",
        "\n",
        "res = llm.invoke(template)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oLk-mKn1JlqG",
        "outputId": "a0d14d1f-1b02-4dfb-978e-8ef2bcef4677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá! Meu nome é [nome não fornecido], sou um redator profissional e estou aqui para ajudar a criar conteúdo de qualidade e atraente para você. Tenho experiência em escrever em vários gêneros, desde artigos e notícias até contos e histórias.\\n\\nMeu objetivo é fornecer informações precisas, interessantes e fáceis de entender. Estou sempre preparado para trabalhar em projetos novos e inovadores, e estou ansioso para ouvir suas ideias e contribuir para o seu sucesso.\\n\\nO que você gostaria de discutir? Quer que eu ajude a criar um texto, ou talvez você tenha uma ideia para um projeto que precise de uma mão extra? Estou aqui para ajudar!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "res.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obYDd3iw4eOB"
      },
      "source": [
        "**Usando com método de template do LangChain**\n",
        "\n",
        "Para criar prompts dinâmicos e organizados, especialmente em aplicações maiores e reutilizáveis com LangChain, utilizamos `ChatPromptTemplate.from_messages()`, que permite inserir de forma organizada variáveis (como {input}) e separar a lógica do prompt, tornando o código mais limpo e escalável.\n",
        "\n",
        "Em vez de invocar a LLM diretamente, criamos uma \"chain\" que combina este template de prompt com o modelo.\n",
        "\n",
        "> Para contextualizar, o que são **chains**: Chain do LangChain (Corrente, Cadeias ou ainda Sequencias) é uma composição de etapas que processam dados em sequência — aqui, a entrada é formatada pelo prompt e enviada ao modelo. A vantagem é que chains permitem combinar várias ações (como formatar, gerar, filtrar, armazenar) de forma modular e reutilizável, facilitando aplicações mais robustas. Elas funcionam ao encadear componentes, onde a saída de um se torna a entrada do próximo, criando uma sequência lógica de operações."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Hpj7zDbCJxOB",
        "outputId": "4ad67c0b-a804-4422-850c-3395f9882bd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá! Eu sou um modelo de linguagem de inteligência artificial, ou seja, um sistema de processamento de linguagem natural (NLP) treinado para entender e gerar texto. Meu objetivo é fornecer informações precisas e relevantes, além de auxiliar em tarefas de redação, edição e comunicação.\\n\\nPosso ajudar com uma ampla gama de tópicos, desde respostas simples até textos mais complexos. Se precisar de ajuda em alguma coisa, basta perguntar! Estou aqui para ajudar.\\n\\nAlém disso, posso oferecer serviços como:\\n\\n- Redação de textos (artigos, posts, etc.)\\n- Edição de textos existentes\\n- Sugestões de conteúdo para redes sociais\\n- Tradução de texto (entre português e inglês)\\n- Respostas a perguntas e dúvidas\\n\\nSe precisar de algo em específico, basta me dizer! Estou aqui para ajudar.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = \"Olá! quem é você?\"  # @param {type:\"string\"}\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Você é um redator profissional\"),\n",
        "    (\"human\", \"{prompt}\")\n",
        "])\n",
        "\n",
        "chain = template | llm\n",
        "\n",
        "res = chain.invoke({\"prompt\": prompt})\n",
        "res.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYlYcZU2pKwS"
      },
      "source": [
        "### Estendendo a chain / Output parser\n",
        "\n",
        "Para trabalhar com a saída de sequência \"crua\" da mensagem, Langchain oferece \"Output Parsers\", como o StrOutputParser, que processa a saída do modelo em um formato mais acessível, convertendo-a em uma string.\n",
        "\n",
        "Se o modelo (LLM) já produz uma string, o StrOutputParser simplesmente a repassa; se for um ChatModel que produz uma mensagem, ele extrai o conteúdo do atributo `.content`. Embora res.content possa ser usado diretamente no caso de modelos LLM que já retornam string, incluir o StrOutputParser na chain é uma boa prática para obter o valor string diretamente, tornando-se especialmente útil ao integrar ChatModels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "2XLak7qGK8zg",
        "outputId": "67529b43-f6e4-4759-d884-5d60b92f8724"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá! Sou um modelo de linguagem avançado, treinado para fornecer informações e responder perguntas em uma variedade de tópicos. Estou aqui para ajudar com qualquer coisa que você precise, desde respostas a perguntas até criar conteúdo de qualidade.\\n\\nSe você precisar de ajuda em algum projeto, estou aqui para:\\n\\n- Redigir textos e artigos\\n- Criar conteúdo para redes sociais\\n- Escrever histórias e relatos\\n- Traduzir textos de um idioma para outro\\n- e muito mais!\\n\\nQual é o seu objetivo ou necessidade? Estou aqui para ajudar!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = \"Olá! quem é você?\"  # @param {type:\"string\"}\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Você é um redator profissional\"),\n",
        "    (\"human\", \"{prompt}\")\n",
        "])\n",
        "\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "res = chain.invoke({\"prompt\": prompt})\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6atxj5X4cytn"
      },
      "source": [
        "## Melhorando a exibição do resultado\n",
        "\n",
        "Note acima que o resultado não ficou tão apresentável no Colab, podemos melhorar a sua visualização usando **Markdown**.\n",
        "* Markdown é uma linguagem de marcação simples e leve que facilita a formatação de texto usando símbolos como asteriscos e hashtags, sem precisar de HTML. No Google Colab, ele melhora a organização e a legibilidade, permitindo destacar textos em *itálico* , **negrito** e criar títulos com #, ## ou ### para diferentes níveis.\n",
        "\n",
        "* Caso queira explorar mais, aqui está um guia da sintaxe: https://www.markdownguide.org/basic-syntax/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "GxS1qO7xLuZU",
        "outputId": "fa04304c-a2be-4afe-f1d5-54eb23e39b19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Olá! Sou um modelo de linguagem avançado, treinado para fornecer informações e responder perguntas em uma variedade de tópicos. Estou aqui para ajudar com qualquer coisa que você precise, desde respostas a perguntas até criar conteúdo de qualidade.\n\nSe você precisar de ajuda em algum projeto, estou aqui para:\n\n- Redigir textos e artigos\n- Criar conteúdo para redes sociais\n- Escrever histórias e relatos\n- Traduzir textos de um idioma para outro\n- e muito mais!\n\nQual é o seu objetivo ou necessidade? Estou aqui para ajudar!"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def show_res(res):\n",
        "  from IPython.display import Markdown\n",
        "  display(Markdown(res))\n",
        "\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbzL38bii-o0"
      },
      "source": [
        "## Juntando em uma função\n",
        "\n",
        "Reunir tudo em uma função facilita a reutilização, organização e manutenção do código, evitando repetições durante nossos testes. Vamos chamar essa função no bloco de código seguinte\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEyMMB28ME0a"
      },
      "outputs": [],
      "source": [
        "def llm_generate(llm, prompt):\n",
        "  template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"Você é um redator profissional.\"),\n",
        "      (\"human\", \"{prompt}\"),\n",
        "  ])\n",
        "\n",
        "  chain = template | llm | StrOutputParser()\n",
        "\n",
        "  res = chain.invoke({\"prompt\": prompt})\n",
        "  show_res(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "snXC2u4EMLa-",
        "outputId": "9b38bfed-3fdf-4108-e31c-98265cc60cfc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Aqui estão 5 dicas de saúde simples e eficazes para melhorar sua qualidade de vida:\n\n**Dica 1: Beba água suficiente**\n\nA hidratação é fundamental para o funcionamento do corpo. Beber água suficiente ajuda a prevenir problemas como:\n\n* Cabeça leve e cansaço\n* Problemas de coordenação motora\n* Infecções urinárias\n* Problemas de pele e cabelo\n\n**Dica 2: Faça exercícios físicos regulares**\n\nO exercício é uma das melhores maneiras de melhorar a saúde e reduzir o risco de doenças crônicas. Alguns benefícios incluem:\n\n* Perda de peso e melhora da forma física\n* Redução do estresse e ansiedade\n* Melhora da saúde do coração\n* Aumento da energia e da resistência\n\n**Dica 3: Coma alimentos saudáveis**\n\nA dieta é fundamental para a manutenção da saúde. Comer alimentos saudáveis ajuda a:\n\n* Prevenir doenças crônicas, como diabetes e doenças cardíacas\n* Reduzir o risco de câncer\n* Melhorar a saúde do sistema imunológico\n* Aumentar a energia e a concentração\n\n**Dica 4: Durma o suficiente**\n\nO sono é fundamental para a recuperação e a manutenção da saúde. Durma o suficiente ajuda a:\n\n* Melhorar a memória e a concentração\n* Reduzir o risco de doenças crônicas\n* Aumentar a energia e a resistência\n* Melhorar a saúde do sistema imunológico\n\n**Dica 5: Pratique a autocompaixão e o autocuidado**\n\nO autocuidado é fundamental para a manutenção da saúde mental e física. Praticar a autocompaixão e o autocuidado ajuda a:\n\n* Reduzir o estresse e a ansiedade\n* Melhorar a saúde do sistema imunológico\n* Aumentar a energia e a resistência\n* Melhorar a qualidade de vida\n\nLembre-se de que a saúde é um processo contínuo e que pequenas mudanças diárias podem fazer uma grande diferença."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"escreva 5 dicas de saúde\"  # @param {type:\"string\"}\n",
        "\n",
        "llm_generate(llm, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2if78TSDTrV"
      },
      "source": [
        "### Outros Modelos Open Source\n",
        "\n",
        "\n",
        " * Modelos disponíveis pelo Groq https://console.groq.com/docs/rate-limits (ver os gratuitos - dentro da aba *free tier*)\n",
        "\n",
        " Durante a fase de experimentação é uma boa ideia testar diferentes modelos.\n",
        "\n",
        "Após validar a nossa solução e fazer os testes iniciais, você pode optar também por modelos pagos e proprietários quando o modelo estiver em produção, já que agora não estará mais desperdiçando alguns centavos de dólar em testes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA9qXy7kDM3n"
      },
      "source": [
        "### Modelos proprietários (exemplo: ChatGPT da OpenAI)\n",
        "\n",
        "Recomenda-se iniciar os testes com modelos open source e, após a validação, migrar para soluções pagas, como ChatGPT (OpenAI) ou Claude (Anthropic), para evitar custos desnecessários durante o desenvolvimento.\n",
        "\n",
        "Soluções pagas oferecem modelos de ponta com alta performance e suporte via API, ideais para robustez e facilidade, mas o custo escala com o uso de tokens (segmentos de texto processados); em contraste, modelos open source, executáveis localmente ou em servidores próprios, proporcionam maior controle, privacidade e custo reduzido para larga escala, exigindo, no entanto, mais conhecimento técnico para configuração e manutenção.\n",
        "\n",
        "A decisão entre API paga e open source deve considerar o volume de uso esperado e a necessidade de personalização.\n",
        "\n",
        "Para testar a implementação, faremos um exemplo com o ChatGPT, lembrando que os custos da OpenAI são baseados em tokens (consulte openai.com/api/pricing/).\n",
        "\n",
        "A grande vantagem de usar LangChain é que toda a sintaxe e lógica de chains criadas são reaproveitáveis, alterando-se apenas a forma como a LLM é carregada, enquanto o restante da aplicação permanece o mesmo.\n",
        "\n",
        "* Valores: https://openai.com/api/pricing/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBMeVJPO5spI"
      },
      "source": [
        "> Como gerar uma API key\n",
        "\n",
        "Para utilizar os modelos da OpenAI, é necessário obter uma chave de API. Siga as etapas abaixo para gerar a sua:\n",
        "\n",
        "1. Acesse o site da OpenAI e faça login na sua conta.\n",
        "2. Navegue até a seção de chaves de API e clique em \"Criar nova chave secreta\" - https://platform.openai.com/api-keys\n",
        "3. Copie a chave gerada e armazene-a em um local seguro. Importante: nunca compartilhe sua chave\n",
        "\n",
        "> Conferir o uso https://platform.openai.com/usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa0-vRacNLa4",
        "outputId": "e498091b-dbc6-4297-faa1-c54590f5bbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "nu4A5QDKNbWb",
        "outputId": "0daaefc9-6505-4316-dc07-ab06ca7783aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'getpass' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2725055923.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'getpass' is not defined"
          ]
        }
      ],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FauddQxaNpM6"
      },
      "outputs": [],
      "source": [
        "# https://platform.openai.com/docs/models\n",
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model = \"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkZqnQ8fOFwV"
      },
      "outputs": [],
      "source": [
        "chatgpt = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "collapsed": true,
        "id": "rp7MKTPYORir",
        "outputId": "cb75ba2a-8507-4c54-de5b-24ee5f9fcfd6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Manter uma boa saúde é fundamental para garantir qualidade de vida e bem-estar ao longo dos anos. Uma das principais dicas é adotar uma alimentação equilibrada, rica em frutas, verduras, legumes e cereais integrais, evitando o consumo excessivo de alimentos processados e açúcares. Além disso, é importante manter-se hidratado, bebendo água regularmente ao longo do dia, o que ajuda no funcionamento adequado do organismo e na eliminação de toxinas. Outra recomendação essencial é a prática regular de atividades físicas, que contribuem para o fortalecimento do sistema cardiovascular, o controle do peso e a melhora do humor.\n\nAlém da alimentação e do exercício, cuidar da saúde mental é igualmente importante. Reservar momentos para o descanso, dormir bem e gerenciar o estresse por meio de técnicas como meditação ou hobbies pode prevenir o surgimento de doenças relacionadas à ansiedade e depressão. Consultas médicas periódicas também são fundamentais para a prevenção e o diagnóstico precoce de possíveis problemas de saúde. Por fim, evitar hábitos nocivos como o tabagismo e o consumo excessivo de álcool ajuda a preservar o organismo e a prolongar a vida com qualidade."
          },
          "metadata": {}
        }
      ],
      "source": [
        "chain_chatgpt = template | chatgpt\n",
        "\n",
        "res = chain_chatgpt.invoke({\"prompt\": \"Gere um texto de 2 parágrafos sobre dicas de saúde\"})\n",
        "show_res(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlkwACT--sje"
      },
      "source": [
        "# Construindo o prompt de aplicação\n",
        "\n",
        "Agora que já interagimos com o modelo de forma básica, vamos começar a explorar a **engenharia de prompt**. Isso significa aprender a formular perguntas ou instruções de forma clara e específica para obter respostas mais precisas e úteis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp-FeN8qLZ27"
      },
      "source": [
        "### Estrutura de um prompt\n",
        "\n",
        "Existem várias técnicas de engenharia de prompt, onde muitas delas se baseiam em princípios parecidos. Uma abordagem simples para construir um prompt mais completo é adicionar a ele alguns 'blocos' (componentes), que no caso seriam:\n",
        "* Papel (Role) - \"quem\" ele deve interpretar (mais sobre isso abaixo)\n",
        "* Tarefa (Task) - tarefa que deve realizar\n",
        "* Entrada (Input) - informação que pode ser usada como contexto para gerar uma resposta (por exemplo o faturamento mensal de uma empresa, ou um dado específico sobre algo ou alguém)\n",
        "* Saída (Output) - como quer que seja o resultado. Podemos especificar também regras, como como tamanho do resultado (medido em quantidade de palavras ou parágrafos por exemplo)\n",
        "* Restrições (Constraints) - o que queremos evitar na resposta. Por exemplo: \"evite jargões ou linguagem muito técnica\". \"Não inclua sua análise ou opinião\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db39X-UhqQhx"
      },
      "source": [
        "### Interpretação de papéis - Role Prompting\n",
        "\n",
        "A técnica de role prompting consiste em instruir o modelo de IA a assumir um papel específico, como um especialista em determinada área (o modo mais comum, conhecido como \"O Especialista\", para obter explicações técnicas), uma figura histórica ou um personagem fictício, o que influencia significativamente o estilo e o conteúdo da resposta, mesmo que o restante do prompt seja idêntico.\n",
        "\n",
        "Utilizar frases como \"Você é um redator\" ou \"Aja como um historiador\" no prompt de sistema são exemplos práticos dessa técnica, que molda a persona da LLM para gerar resultados mais alinhados com o contexto desejado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "FCyEzLAkg_8C",
        "outputId": "f45ed6f3-057b-4975-ccb0-ca491ee318e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O chocolate é um dos alimentos mais antigos e versáteis da história humana. Sua origem remonta à América Central, onde os astecas e maias cultivavam a cacaúa, planta que produz as nozes amargas de chocolate, há mais de 3.000 anos. A partir da Colômbia, o chocolate foi levado para a América do Sul e, posteriormente, para a Europa, onde se tornou um luxo para os nobres e ricos durante a Idade Média. Com a descoberta da América pelo navegador Cristóvão Colombo em 1492, o chocolate começou a ser comercializado em larga escala, tornando-se uma das principais comodidades do período colonial. Hoje em dia, o chocolate é um dos produtos alimentícios mais consumidos no mundo, com uma variedade de sabores e texturas que agradam a todos os gostos."
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"fale sobre chocolate em 1 parágrafo\"\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Você é um historiador\"),\n",
        "    (\"human\", \"{prompt}\")\n",
        "])\n",
        "\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "res = chain.invoke({\"prompt\": prompt})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTC8_Br46dzv"
      },
      "source": [
        "Aqui vemos então como o tipo de especialista pode impactar totalmente no resultado. Portanto precisamos pedir algo que seja alinhado ao nosso propósito (copiamos o mesmo código do bloco acima, mudando apenas o prompt do system)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "PAp2LYHphgTb",
        "outputId": "21bd2c5f-b4b9-406b-a6b9-e681691fecae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O chocolate! Uma das delícias mais amadas em todo o mundo. Com sua rica história que remonta à antiguidade, o chocolate é mais do que apenas um lindo e saboroso doce. É uma experiência sensorial que pode ser experimentada de muitas formas, desde chocolates com cobertura até barras de chocolate artesanais. Além das suas deliciosas cores, cheiros e sabores, o chocolate tem também propriedades benéficas para a saúde, como reduzir o estresse e melhorar o humor. Com sua versatilidade e diversidade, é fácil ver por que o chocolate é um dos produtos mais populares e desejados em todo o mundo."
          },
          "metadata": {}
        }
      ],
      "source": [
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Você é um especialista em marketing digital.\"),\n",
        "    (\"human\", \"{prompt}\"),\n",
        "])\n",
        "\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "res = chain.invoke({\"prompt\": prompt})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XewkEjvS67ZK"
      },
      "source": [
        "Ser mais específico geralmente é mais indicado. No contexto da nossa aplicação o prompt abaixo funciona melhor porque direciona o modelo não apenas para produzir textos bem escritos, mas com foco estratégico (como conversão, engajamento e SEO, que são essenciais em campanhas de marketing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "ZfG4jp1ghw7e",
        "outputId": "3cb7677b-afd3-452b-e829-1a76280c5e1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O chocolate! Uma delícia que não apenas agradecemos ao paladar, mas também ao coração. Com suas notas cítricas e nutricionais, é inevitável se sentir atraído pela riqueza e pela sutileza desse lindo alimento. Desde a antiga civilização maias, o chocolate foi um símbolo de amor e luxo, e sua popularidade só cresceu ao longo do tempo. Com sabores e texturas variados, o chocolate é mais do que apenas um doce, é uma experiência sensorial que pode ser apreciada em diferentes momentos, desde um momento de relaxamento, até uma celebração especial. E, é claro, o chocolate também é uma excelente fonte de antioxidantes e minerais, tornando-o uma escolha saudável para quem não quer renunciar ao prazer."
          },
          "metadata": {}
        }
      ],
      "source": [
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Você é um especialista em marketing digital com foco em SEO e escrita persuasiva.\"),\n",
        "    (\"human\", \"{prompt}\"),\n",
        "])\n",
        "\n",
        "chain = template | llm | StrOutputParser()\n",
        "\n",
        "res = chain.invoke({\"prompt\": prompt})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_l8yU2Brmth"
      },
      "source": [
        "### Usando exemplos - One-Shot e Few-Shot Prompting\n",
        "\n",
        " * Zero-Shot – O modelo responde sem exemplos, confiando apenas no treinamento\n",
        " * One-Shot – Um exemplo é fornecido para orientar a resposta.\n",
        " * Few-Shot – Vários exemplos ajudam o modelo a reconhecer padrões e melhorar a precisão.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "PeCnOWfnilZb",
        "outputId": "f24dd90f-5560-4325-c8fd-a52b19ab620a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Título: Você sabia que comer chocolate pode melhorar sua mente?\n\nTexto: O chocolate contém substâncias químicas que podem aumentar a produção de dopamina, um neurotransmissor associado à felicidade e satisfação. Além disso, o chocolate também contém flavonoides que podem melhorar a memória e a concentração. Mas lembre-se de escolher chocolates com ingredientes naturais e sem aditivos artificiais para aproveitar ao máximo esses benefícios!\n\nHashtags: #chocolate #mente #saúde"
          },
          "metadata": {}
        }
      ],
      "source": [
        "assunto = 'chocolate'\n",
        "\n",
        "one_shot = f\"\"\"\n",
        "Exemplo:\n",
        "Título: Você sabia que beber mais água pode melhorar sua concentração?\n",
        "Texto: A desidratação leve já é suficiente para reduzir seu foco e energia no dia a dia. Mantenha uma garrafinha por perto e lembre-se de se hidratar ao longo do dia.\n",
        "Hashtags: #hidratação #foconasaude\n",
        "\n",
        "Agora gere um novo texto que fale sobre {assunto}\n",
        "\"\"\"\n",
        "\n",
        "#print(one_shot)\n",
        "\n",
        "res = chain.invoke({\"prompt\": one_shot})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMdXiXAi7Zur"
      },
      "source": [
        "O few-shot prompting, ou prompt com exemplos, demonstra à IA a estrutura, estilo e abordagem desejados para a resposta, como a inclusão de hashtags ou a formulação de títulos como perguntas, tornando o processo de instrução mais intuitivo e eficiente do que apenas fornecer instruções textuais. Embora exemplos possam ser combinados com texto para maior precisão, o few-shot prompting com múltiplos exemplos, como o que veremos a seguir, ajuda a IA a generalizar melhor o padrão esperado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "0MRk-dVojUp7",
        "outputId": "906f1a85-5647-4f20-cb29-c96eed35c1da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Exemplo 3:\nTítulo: Chocolate pode ser saudável? Descubra!\nTexto: Você acha que o chocolate é um inimigo da saúde? Pense novamente! O chocolate preto, feito com ingredientes naturais, pode ajudar a reduzir o estresse e melhorar a memória. Além disso, é uma fonte rica em antioxidantes. Para aproveitar ao máximo os benefícios do chocolate, escolha variedades sem aditivos e coma em moderação.\nHashtags: #chocolate #saudável #nutrição"
          },
          "metadata": {}
        }
      ],
      "source": [
        "few_shot = f\"\"\"\n",
        "Exemplo 1:\n",
        "Título: Você sabia que beber mais água pode melhorar sua concentração?\n",
        "Texto: A desidratação leve já é suficiente para reduzir seu foco e energia no dia a dia. Mantenha uma garrafinha por perto e lembre-se de se hidratar ao longo do dia.\n",
        "Hashtags: #hidratação #foconasaude\n",
        "\n",
        "Exemplo 2:\n",
        "Título: Comer carboidratos à noite engorda: Mito ou verdade?\n",
        "Texto: Esse é um mito comum. O que realmente importa é o total calórico do dia e a qualidade dos alimentos. Com orientação certa, dá sim para comer bem à noite sem culpa!\n",
        "Hashtags: #nutricaosemmitos #equilibrioalimentar\n",
        "\n",
        "Agora gere um novo texto que fale sobre {assunto}\n",
        "\"\"\"\n",
        "\n",
        "res = chain.invoke({\"prompt\": few_shot})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWN_JIw81arr"
      },
      "source": [
        "### Guiando o resultado com uma estrutura - Structured Prompting\n",
        "\n",
        "Para o prompt final de nossa aplicação, usaremos também o conceito de Prompting estruturado (Structured Prompting), cuja premissa envolve a codificação cuidadosa de instruções, exemplos e restrições personalizadas para direcionar propositalmente comportamentos de modelos de linguagem para tarefas de um nicho específicos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "96234e8cf1644f379c82137a3349e6ad",
            "35e36a5f82874bfcbad64d900666e321",
            "e2bdab56ce824ca9b908fae804ab7425",
            "b69ba16998b24b95943171e9e07dbee2",
            "9c8890cd00a44c29987fb02bfade45f8",
            "0fb2156884344740a342a0a51f91787a",
            "300a1da0f87d4c20930b8236cb921313",
            "27ba1b96670c409eaed4d6e37b1263da",
            "a60140076ead460c8c0e0bc3311eeeba",
            "94212f66ad5748e09a47f257c4f54afc",
            "019ed3585d9346128b8830ab024d2949",
            "f258888580da46e7aed44538602a9e13",
            "f0304498b77c4e9eb71516cb328f4bf6",
            "129c8443633b49fd94e7913c9734ada4",
            "0299e82c52304d8ca88cf41c50d4eed5",
            "e3c621de95624683a77b4c80f86212e6",
            "0a9c2ec91404485db7a7b0a812e11b16",
            "0ee1ecf9e84d4eb2b6da834c753feaa8",
            "23b14597e67b4af3a89f56afd424565d",
            "34fff4152d54492c974ba0e3117e792e",
            "271de9033b78475cb8bbfded02cac237",
            "cc1d9c4773e44f3b92649b8d5d256c0d",
            "b1429d3fc8d249beb273cb64ecf2acf5",
            "5056d268d76d4d3499273dc378a50e0d",
            "d39913c90fe04fca8d19bd4915b8db82",
            "ed24be2c4aec43f889017ec3aab86a50",
            "7aa393414c6948c5b164d2b9f09eb21c",
            "5f7751ccecc245789af2a84301bc3a21",
            "bb519a8ea337412a8eb4d5382266552a",
            "3e6f46a0afac4de8bf4419a0b0a0ddb6",
            "e9b2689633f04d478b50e8245be2c121"
          ]
        },
        "id": "z6UO0IdQmu34",
        "outputId": "c44d31b7-249b-4f25-92ea-e64aa61ff4c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Tema:', layout=Layout(width='500px'), placeholder='Ex: saúde mental…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96234e8cf1644f379c82137a3349e6ad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "form = create_form()\n",
        "display(form)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX7ji896nVsF",
        "outputId": "7c968cc0-098e-4824-f9d7-a8c47dee1a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Crie um post para Instagram com a seguinte estrutura:\n",
            "1. Comece com uma pergunta provocativa.\n",
            "2. Apresente um benefício claro relacionado ao tema.\n",
            "3. Finalize com uma chamada para ação (CTA) encorajando o leitor a buscar mais informações.\n",
            "\n",
            "Tema: \n",
            "Público-alvo: Geral\n",
            "Tom: Normal\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Crie um post para {platform.value} com a seguinte estrutura:\n",
        "1. Comece com uma pergunta provocativa.\n",
        "2. Apresente um benefício claro relacionado ao tema.\n",
        "3. Finalize com uma chamada para ação (CTA) encorajando o leitor a buscar mais informações.\n",
        "\n",
        "Tema: {topic.value}\n",
        "Público-alvo: {audience.value}\n",
        "Tom: {tone.value}\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Ox7xideSnocJ",
        "outputId": "11e9621e-11ec-42e2-c1df-1be5d6cc1cef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Post para Instagram:**\n\n\"Você está perdendo tempo e dinheiro investindo em marketing que não está funcionando? \n\nVocê sabia que uma estratégia de SEO bem planejada pode aumentar a visibilidade da sua empresa em até 500% e gerar mais leads de qualidade?\n\nCom uma boa estratégia de SEO, você pode:\n\n- Aumentar a visibilidade da sua empresa em motores de busca\n- Aumentar o tráfego de visitantes para o seu site\n- Gerar mais leads de qualidade e conversões\n\nQuer saber mais sobre como implementar uma estratégia de SEO eficaz para a sua empresa? Clique no link na nossa bio e descubra como podemos ajudar a impulsionar o seu negócio!\n\n#SEO #MarketingDigital #GrowthHacking #Empreendedorismo\""
          },
          "metadata": {}
        }
      ],
      "source": [
        "res = chain.invoke({\"prompt\": prompt})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1JjJIP_uG7P"
      },
      "source": [
        "Para dar mais liberdade à IA na escolha da estrutura do texto, especialmente considerando que a aplicação aceitará diversos parâmetros como plataforma e comprimento, optaremos por um prompt final dinâmico em vez de um structured prompting rígido, que seria mais adequado para resultados muito específicos e poderia levar a publicações repetitivas.\n",
        "\n",
        "### Construindo o prompt final dinamicamente\n",
        "\n",
        "\n",
        "Este prompt final será construído a partir das variáveis do formulário, organizado em itens legíveis com `-` para fácil modificação e escalabilidade.\n",
        "\n",
        "Cada linha fornecerá instruções claras (canal, tom, público...), e opções como hashtags ou CTAs serão incluídas condicionalmente usando expressões inline em Python, adaptando o prompt às escolhas do usuário.\n",
        "\n",
        "Adicionaremos também a instrução para garantir que a saída seja limpa e pronta para uso.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld5qtMlzoSC6",
        "outputId": "869cbbf4-c101-47cf-9cb4-40299c9c9265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Escreva um texto com SEO otimizado sobre o tema ''.\n",
            "Retorne em sua resposta apenas o texto final.\n",
            "- Onde será publicado: Instagram.\n",
            "- Tom: Normal.\n",
            "- Público-alvo: Geral.\n",
            "- Comprimento: Curto.\n",
            "- Não inclua chamada para ação\n",
            "- Não inclua hashtags.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Escreva um texto com SEO otimizado sobre o tema '{topic.value}'.\n",
        "Retorne em sua resposta apenas o texto final.\n",
        "- Onde será publicado: {platform.value}.\n",
        "- Tom: {tone.value}.\n",
        "- Público-alvo: {audience.value}.\n",
        "- Comprimento: {length.value}.\n",
        "- {\"Inclua uma chamada para ação clara.\" if cta.value else \"Não inclua chamada para ação\"}\n",
        "- {\"Retorne ao final do texto hashtags relevantes.\" if hashtags.value else \"Não inclua hashtags.\"}\n",
        "{\"- Palavras-chave que devem estar presentes nesse texto (para SEO): \" + keywords.value if keywords.value else \"\"}\n",
        "\"\"\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "BMgYLNeZo6pM",
        "outputId": "363b4807-1afa-4870-cd88-95b45a09610e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\"Desbloqueie seu potencial! Acredite em você mesmo e não tenha medo de sonhar alto. A confiança é a chave para alcançar seus objetivos e superar desafios. Não deixe que a insegurança o impeça de perseguir seus sonhos. Você é capaz de fazer mais do que imagina, apenas acredite em si mesmo.\""
          },
          "metadata": {}
        }
      ],
      "source": [
        "res = chain.invoke({\"prompt\": prompt})\n",
        "show_res(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHWt3Tf38lpZ"
      },
      "source": [
        "### Sobre o prompt e melhorias\n",
        "\n",
        "Não existe um “melhor prompt” universal — o mais eficaz depende sempre do seu objetivo e do contexto da aplicação. A melhor forma de descobrir o que funciona é testando variações e analisando os resultados.\n",
        "\n",
        "Para encontrar boas alternativas, você pode:\n",
        "\n",
        "* Pesquisar por prompt books gratuitos disponíveis na internet\n",
        "\n",
        "* Usar sites que reúnem templates prontos, como PromptHero ou FlowGPT\n",
        "\n",
        "* Pedir sugestões diretamente à própria LLM (“Como posso melhorar esse prompt para torná-lo mais persuasivo?”)\n",
        "\n",
        "* Analisar exemplos de prompts usados em casos reais ou estudos de caso\n",
        "\n",
        "* Ajustar pequenos trechos do prompt e observar o impacto (tom, foco, estrutura)\n",
        "\n",
        "* Extra: Combinar técnicas (por exemplo Structured Prompting com few-shot prompting) pode aprimorar ainda mais a qualidade e a relevância dos conteúdos gerados.\n",
        "\n",
        "Essas estratégias ajudam a refinar continuamente a performance e alinhar melhor o conteúdo gerado aos seus objetivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zT7AsmWEr6M"
      },
      "source": [
        "# Concluindo a aplicação final\n",
        "\n",
        "Agora que concluímos a criação do prompt final de nossa aplicação, podemos partir para a finalização.\n",
        "Precisamos juntar os formulários ao prompt e à LLM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acUVj5FitObw"
      },
      "outputs": [],
      "source": [
        "def llm_generate(llm, prompt):\n",
        "  template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"Você é um especialista em marketing digital com foco em SEO e escrita persuasiva.\"),\n",
        "      (\"human\", \"{prompt}\"),\n",
        "  ])\n",
        "\n",
        "  chain = template | llm | StrOutputParser()\n",
        "\n",
        "  res = chain.invoke({\"prompt\": prompt})\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9Lvtuc5tab7"
      },
      "outputs": [],
      "source": [
        "def generate_result(b):\n",
        "  with output:\n",
        "    output.clear_output()\n",
        "    prompt = f\"\"\"\n",
        "    Escreva um texto com SEO otimizado sobre o tema '{topic.value}'.\n",
        "    Retorne em sua resposta apenas o texto final e não inclua ela dentro de aspas.\n",
        "    - Onde será publicado: {platform.value}.\n",
        "    - Tom: {tone.value}.\n",
        "    - Público-alvo: {audience.value}.\n",
        "    - Comprimento: {length.value}.\n",
        "    - {\"Inclua uma chamada para ação clara.\" if cta.value else \"Não inclua chamada para ação\"}\n",
        "    - {\"Retorne ao final do texto hashtags relevantes.\" if hashtags.value else \"Não inclua hashtags.\"}\n",
        "    {\"- Palavras-chave que devem estar presentes nesse texto (para SEO): \" + keywords.value if keywords.value else \"\"}\n",
        "    \"\"\"\n",
        "    try:\n",
        "      res = llm_generate(llm, prompt)\n",
        "      show_res(res)\n",
        "    except Exception as e:\n",
        "      print(f\"Erro: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cpcv3AT9FWu"
      },
      "source": [
        "Para executar a função de geração de conteúdo ao clicar no botão, precisamos primeiro desvincular qualquer callback anterior para evitar execuções duplicadas, especialmente em ambientes como o Colab onde o parâmetro remove=True pode apresentar instabilidades. A solução mais simples e robusta é redeclarar o output, o generate_button (associando o on_click à nova função) e a variável form chamando create_form(), garantindo uma configuração limpa a cada execução da célula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cBwBeYOttYw"
      },
      "outputs": [],
      "source": [
        "output = widgets.Output()\n",
        "generate_button = widgets.Button(description = \"Gerar conteúdo\")\n",
        "generate_button.on_click(generate_result)\n",
        "form = create_form()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "42d2b18b2d7a4c159732d64e04caa01a",
            "35e36a5f82874bfcbad64d900666e321",
            "e2bdab56ce824ca9b908fae804ab7425",
            "b69ba16998b24b95943171e9e07dbee2",
            "9c8890cd00a44c29987fb02bfade45f8",
            "0fb2156884344740a342a0a51f91787a",
            "300a1da0f87d4c20930b8236cb921313",
            "27ba1b96670c409eaed4d6e37b1263da",
            "a60140076ead460c8c0e0bc3311eeeba",
            "974efff07f8d48e5aa09830ab30df83a",
            "19ea002d58844c5c900558c5c559f691",
            "c4106067fbe347508f84f40ccfe88a53",
            "f0304498b77c4e9eb71516cb328f4bf6",
            "129c8443633b49fd94e7913c9734ada4",
            "0299e82c52304d8ca88cf41c50d4eed5",
            "e3c621de95624683a77b4c80f86212e6",
            "0a9c2ec91404485db7a7b0a812e11b16",
            "0ee1ecf9e84d4eb2b6da834c753feaa8",
            "23b14597e67b4af3a89f56afd424565d",
            "34fff4152d54492c974ba0e3117e792e",
            "271de9033b78475cb8bbfded02cac237",
            "cc1d9c4773e44f3b92649b8d5d256c0d",
            "b1429d3fc8d249beb273cb64ecf2acf5",
            "5056d268d76d4d3499273dc378a50e0d",
            "d39913c90fe04fca8d19bd4915b8db82",
            "ed24be2c4aec43f889017ec3aab86a50",
            "7aa393414c6948c5b164d2b9f09eb21c",
            "5f7751ccecc245789af2a84301bc3a21",
            "6c1f5313ebce4feeae0def861333595e",
            "ce644390b53043459b15c5bedafadac9",
            "7c04dd45c27446ceb1a68a6f04ecc37b"
          ]
        },
        "id": "LtF8a2gOuCO4",
        "outputId": "7126e2df-9eb5-410d-c44a-2dc1af53c70a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Tema:', layout=Layout(width='500px'), placeholder='Ex: saúde mental…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42d2b18b2d7a4c159732d64e04caa01a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(form)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4LewhCK9atG"
      },
      "source": [
        "**Pronto!** Finalizamos nossa aplicação.\n",
        "\n",
        "Aqui você pode reunir todo o código desenvolvido em um único bloco, já pronto para ser executado e utilizado por quem for operar o sistema.\n",
        "\n",
        "Para deixar o código recolhido por padrão, utilize o comando `#@title` no início do bloco — por exemplo: `#@title Rodar Aplicação`\n",
        "Isso além de criar uma seção com título e facilitar a organização vai permitir que o código fique escondido. Para exibir ou ocultar o conteúdo, basta dar dois cliques sobre o título (\"Rodar Aplicação\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjbhV9TBZrBV"
      },
      "source": [
        "## Escalando para outras áreas e adicionando mais campos\n",
        "\n",
        "Para aumentar a flexibilidade na definição das opções dos campos Dropdown, em vez de fixá-las no código, utilizaremos os formulários do Colab com a anotação `@param {type:\"string\"}`. Isso permite que o usuário insira uma lista de valores separados por vírgula diretamente em um campo ao lado da célula de código, que é então convertida em uma lista Python e usada dinamicamente no parâmetro options do widget.\n",
        "\n",
        "Dessa forma, o formulário se torna totalmente configurável, permitindo fácil adição ou modificação das opções dos dropdowns, como as do campo \"comprimento\", sem alterar o código principal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OpXFWo_v39l",
        "outputId": "9ef657c9-0cdb-4e5b-fc1b-a0315926bf5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Curto, Médio, Longo, 1 parágrafo, 1 página\n"
          ]
        }
      ],
      "source": [
        "opt_length = \"Curto, Médio, Longo, 1 parágrafo, 1 página\" # @param {type:\"string\"}\n",
        "print(opt_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOtCKjXBwB70"
      },
      "outputs": [],
      "source": [
        "options_length = [x.strip() for x in opt_length.split(\",\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-epEz2bXwLNh",
        "outputId": "f1c0bc25-df13-441a-c96a-1a42e1737b81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Curto', 'Médio', 'Longo', '1 parágrafo', '1 página']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "options_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oigZEKWwPtU"
      },
      "outputs": [],
      "source": [
        "length = widgets.Dropdown(\n",
        "    options = opt_length,\n",
        "    description=\"Tamanho\",\n",
        "    layout=widgets.Layout(width=w_dropdown)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "da3c6b686b2e455581ae242aa9e8e4cb",
            "35e36a5f82874bfcbad64d900666e321",
            "e2bdab56ce824ca9b908fae804ab7425",
            "b69ba16998b24b95943171e9e07dbee2",
            "0f6ca7d0a9344f1388fee1bf76039d96",
            "0fb2156884344740a342a0a51f91787a",
            "300a1da0f87d4c20930b8236cb921313",
            "27ba1b96670c409eaed4d6e37b1263da",
            "a60140076ead460c8c0e0bc3311eeeba",
            "974efff07f8d48e5aa09830ab30df83a",
            "19ea002d58844c5c900558c5c559f691",
            "3d47f5cd828c40b892f5724333c9a806",
            "f0304498b77c4e9eb71516cb328f4bf6",
            "129c8443633b49fd94e7913c9734ada4",
            "0299e82c52304d8ca88cf41c50d4eed5",
            "e3c621de95624683a77b4c80f86212e6",
            "0a9c2ec91404485db7a7b0a812e11b16",
            "0ee1ecf9e84d4eb2b6da834c753feaa8",
            "75b1c58cbe8a461db6fbd40ccdcb8456",
            "f7d3c33e0bfa4628ad97c7b526921a0c",
            "271de9033b78475cb8bbfded02cac237",
            "cc1d9c4773e44f3b92649b8d5d256c0d",
            "b1429d3fc8d249beb273cb64ecf2acf5",
            "5056d268d76d4d3499273dc378a50e0d",
            "d39913c90fe04fca8d19bd4915b8db82",
            "ed24be2c4aec43f889017ec3aab86a50",
            "7aa393414c6948c5b164d2b9f09eb21c",
            "5f7751ccecc245789af2a84301bc3a21",
            "6c1f5313ebce4feeae0def861333595e",
            "ce644390b53043459b15c5bedafadac9",
            "7c04dd45c27446ceb1a68a6f04ecc37b"
          ]
        },
        "id": "YdQslR84wcWV",
        "outputId": "f1b96c90-381d-496b-e37a-44a39f4532db"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Text(value='', description='Tema:', layout=Layout(width='500px'), placeholder='Ex: saúde mental…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da3c6b686b2e455581ae242aa9e8e4cb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "form = create_form()\n",
        "output.clear_output()\n",
        "display(form)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAkQg3nfwWcc"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Construção de interface com Streamlit\n",
        "\n",
        "Após validar que nossa aplicação está funcionando corretamente, podemos aprimorar ainda mais a interface.\n",
        "\n",
        "Embora o uso de ipywidgets pode ser funcional, conseguimos criar uma experiência mais amigável e visual com o **Streamlit** — uma ferramenta focada em interfaces interativas para aplicações em Python. Além disso, o Streamlit facilita o deploy da aplicação, tornando-a mais acessível para equipes de atendimento ou até mesmo clientes finais.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG0es1WC-NHL"
      },
      "source": [
        "\n",
        "### 1. Instalação do Streamlit\n",
        "\n",
        "Para começarmos, precisamos instalar o **Streamlit**\n",
        "\n",
        "Por estarmos rodando no Colab, precisa também instalar o **Localtunnel** para conseguirmos nos conectar à aplicação gerada com o streamlit. Ao executar em seu próprio computador ela não é necessária, pois após rodar o comando de launch do streamlit (\"streamlit run ...\") será aberto automaticamente uma aba em seu navegador com a aplicação.\n",
        "\n",
        "Além disso, vamos instalar a biblioteca **dotenv**, usada para simplificar a gestão de variáveis de ambiente ao armazená-las em um arquivo .env.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KoANN51zn1F",
        "outputId": "47ae9752-0947-48cb-c30a-cb5ee8367d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 2s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!npm install -q localtunnel\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD45ShZ_G9hd"
      },
      "source": [
        "### 2. Criação do arquivo da aplicação\n",
        "\n",
        "Crie um arquivo chamado `app.py` (ou outro nome que preferir) com o conteúdo do seu código adaptado para Streamlit.\n",
        "\n",
        "Antes de colocarmos o código nesse arquivo, vamos criar o arquivo .env, para carregar as variáveis de ambiente. Aqui basta colocarmos a key do Groq, a mesma que usamos anteriormente. Deixe nesse formato: `GROQ_API_KEY=CHAVE_AQUI`\n",
        "\n",
        "* Obs: o comando `%%writefile` no início desse bloco de código permite que a célula do notebook seja salva como um arquivo externo, com o nome especificado. Ou seja, estamos criando um arquivo com esse nome e o conteúdo será tudo a partir da segunda linha do bloco abaixo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU6Ey3_J0QSM",
        "outputId": "f56ee8f9-2e52-49aa-f4ae-8e331f2aff77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ],
      "source": [
        "%%writefile .env\n",
        "GROQ_API_KEY="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1NIQ6R-fLb"
      },
      "source": [
        "Foi necessário fazer algumas adaptações ao código, pois até então usamos ipywidgets mas agora no Streamlit usaremos funções da própria biblioteca para criar os campos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2IpNQJX0kJp",
        "outputId": "6fb81dfa-7f7c-4a84-f36f-51a0638d8453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "## conexão com a LLM\n",
        "id_model = \"llama3-70b-8192\"\n",
        "llm = ChatGroq(\n",
        "    model=id_model,\n",
        "    temperature=0.7,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "## função de geração\n",
        "def llm_generate(llm, prompt):\n",
        "  template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"Você é um especialista em marketing digital com foco em SEO e escrita persuasiva.\"),\n",
        "      (\"human\", \"{prompt}\"),\n",
        "  ])\n",
        "\n",
        "  chain = template | llm | StrOutputParser()\n",
        "\n",
        "  res = chain.invoke({\"prompt\": prompt})\n",
        "  return res\n",
        "\n",
        "st.set_page_config(page_title = \"Gerador de conteúdo 🤖\", page_icon=\"🤖\")\n",
        "st.title(\"Gerador de conteúdo\")\n",
        "\n",
        "# Campos do formulário\n",
        "topic = st.text_input(\"Tema:\", placeholder=\"Ex: saúde mental, alimentação saudável, prevenção, etc.\")\n",
        "platform = st.selectbox(\"Plataforma:\", ['Instagram', 'Facebook', 'LinkedIn', 'Blog', 'E-mail'])\n",
        "tone = st.selectbox(\"Tom:\", ['Normal', 'Informativo', 'Inspirador', 'Urgente', 'Informal'])\n",
        "length = st.selectbox(\"Tamanho:\", ['Curto', 'Médio', 'Longo'])\n",
        "audience = st.selectbox(\"Público-alvo:\", ['Geral', 'Jovens adultos', 'Famílias', 'Idosos', 'Adolescentes'])\n",
        "cta = st.checkbox(\"Incluir CTA\")\n",
        "hashtags = st.checkbox(\"Retornar Hashtags\")\n",
        "keywords = st.text_area(\"Palavras-chave (SEO):\", placeholder=\"Ex: bem-estar, medicina preventiva...\")\n",
        "\n",
        "if st.button(\"Gerar conteúdo\"):\n",
        "  prompt = f\"\"\"\n",
        "  Escreva um texto com SEO otimizado sobre o tema '{topic}'.\n",
        "  Retorne em sua resposta apenas o texto final e não inclua ela dentro de aspas.\n",
        "  - Onde será publicado: {platform}.\n",
        "  - Tom: {tone}.\n",
        "  - Público-alvo: {audience}.\n",
        "  - Comprimento: {length}.\n",
        "  - {\"Inclua uma chamada para ação clara.\" if cta else \"Não inclua chamada para ação\"}\n",
        "  - {\"Retorne ao final do texto hashtags relevantes.\" if hashtags else \"Não inclua hashtags.\"}\n",
        "  {\"- Palavras-chave que devem estar presentes nesse texto (para SEO): \" + keywords if keywords else \"\"}\n",
        "  \"\"\"\n",
        "  try:\n",
        "      res = llm_generate(llm, prompt)\n",
        "      st.markdown(res)\n",
        "  except Exception as e:\n",
        "      st.error(f\"Erro: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsn5BtDYHD5w"
      },
      "source": [
        "### 3. Execução do Streamlit\n",
        "\n",
        "Tendo nosso script pronto, basta executar o comando abaixo para rodar a nossa aplicação pelo streamlit.\n",
        "Isso fará com que a aplicação do Streamlit seja executada em segundo plano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmR2qoRb1Y0B"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmQclRR_-s7N"
      },
      "source": [
        "> **Como abrir a interface**\n",
        "\n",
        "> Importante: caso esse código não funcione corretamente use o ngrok, cujo código você encontra mais abaixo (para mais detalhes, veja a aula 'Aviso sobre uso no Colab')\n",
        "\n",
        "* Antes de conectar com o localtunnel, você precisa obter o IP externo (usando esse comando `!wget -q -O - ipv4.icanhazip.com`). Copie esse número, que vai aparecer na saída do bloco abaixo (após rodar)\n",
        "* Então, entre no link que aparece na saída do bloco abaixo e informe esse IP no campo Tunnel Password. Logo em seguida, clique no botão e aguarde a interface ser inicializada\n",
        "\n",
        "\n",
        "Esse comando usa npx localtunnel para \"expor\" o aplicativo Streamlit em execução local para a internet. O aplicativo é hospedado na porta 8501, e o localtunnel fornece uma URL pública por meio da qual o aplicativo pode ser acessado.\n",
        "\n",
        "**Caso não abra, reinicie a sessão e espere alguns segundos antes de clicar no link. Ou, reinicie o ambiente de execução e rode os comandos novamente.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVirNH_q1im2",
        "outputId": "b643beb1-9c6d-47c2-cb1f-1a42e039a00f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.126.125.82\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://cold-humans-lay.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5He9yLbyF3yC"
      },
      "source": [
        "> **Importante:** Caso o comando acima com localtunnel não funcione, use o código abaixo (Para mais detalhes, consulte a aula \"Aviso sobre uso no Colab\" da seção 2)\n",
        "\n",
        "### Alternativa com ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qaR3mKpIBkF"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "l65HOJRLF5B2",
        "outputId": "c93308a2-ae61-46eb-f0d0-c28121f961de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-09-25T22:23:28+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: SEU_TOKEN_AQUI\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-25T22:23:28+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: SEU_TOKEN_AQUI\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-25T22:23:28+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: SEU_TOKEN_AQUI\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: SEU_TOKEN_AQUI\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2371359666.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'streamlit run app.py --server.port 8501 &>/content/logs.txt &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: SEU_TOKEN_AQUI\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n."
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok config add-authtoken SEU_TOKEN_AQUI\n",
        "!streamlit run app.py --server.port 8501 &>/content/logs.txt &\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILPHOF-b2wUC"
      },
      "source": [
        "---\n",
        "\n",
        "## Rodando a LLM localmente\n",
        "\n",
        "Se for um modelo open source nós podemos fazer o download e rodar localmente em um provedor cloud (como nesse caso o colab) ou em nosso próprio computador.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJumPP25-46R"
      },
      "source": [
        "### -> Para executar no Colab\n",
        "\n",
        "**Importante:** Antes de realizar os próximos passos, mude o ambiente de execução no Colab para usar GPU, que será necessário já que todo o processamento será feito direto localmente no ambiente de execução do Colab. Para isso, selecione 'Ambiente de execução > Alterar o tipo de ambiente de execução' e na opção 'Acelerador de hardware' selecione 'GPU'.\n",
        "\n",
        "Além das bibliotecas do langchain que instalamos, vamos precisar também da biblioteca `langchain-huggingface`, `transformers` e `bitsandbytes`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTQsXgEvA-_b"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-huggingface transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD7uUgANBCEz"
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes-cuda110 bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOh9vNBjBjLK"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoICDmhc-9vv"
      },
      "source": [
        "**Quantização**\n",
        "\n",
        "A execução de LLMs pode ser desafiadora devido aos recursos limitados, especialmente na versão gratuita do Google Colab. Para contornar essa limitação, além de escolher modelos com menos parâmetros podemos usar técnicas de quantização, como o `BitsAndBytesConfig` da biblioteca `transformers`, que permitem carregar e executar modelos massivos de forma eficiente sem comprometer significativamente o desempenho.\n",
        "* Essas técnicas reduzem os custos de memória e computação ao representar pesos e ativações com tipos de dados de menor precisão, como inteiros de 8 bits (int8) ou até 4 bits, tornando viável o uso de modelos grandes mesmo em hardware limitado.\n",
        "* Alternativas ao BitsAndBytesConfig: AutoGPTQ, AutoAWQ, etc.\n",
        "* Para quem prefere evitar configurações complexas de otimização e manter a máxima qualidade, considere o uso via API.\n",
        "* Mais detalhes sobre quantização: https://huggingface.co/blog/4bit-transformers-bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjWkkHRLB7Z6"
      },
      "outputs": [],
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZPRa_Fj_Bnh"
      },
      "source": [
        "**Download do modelo**\n",
        "\n",
        "Agora faremos o download e a configuração de um modelo do HuggingFace usando o método `AutoModelForCausalLM.from_pretrained`. Este processo pode levar alguns minutos, pois o modelo tem alguns GB - mas no geral o download no Colab deve ser relativamente rápido.\n",
        "\n",
        "> Para ver todos os modelos disponíveis no Hugging Face, acesse: https://huggingface.co/models?pipeline_tag=text-generation\n",
        "\n",
        "Escolhemos o Phi 3 (microsoft/Phi-3-mini-4k-instruct), um modelo menor mas que demonstrou ser muito interessante e com ótimo custo benefício\n",
        " - https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6NjIJUoCRn2"
      },
      "outputs": [],
      "source": [
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj5q220U_Ikk"
      },
      "source": [
        "**Criação do Pipeline**\n",
        "\n",
        "Agora criaremos um pipeline para geração de texto usando nosso modelo e tokenizer carregados anteriormente. A função de pipeline HuggingFace simplifica o processo de execução de várias tarefas de processamento de linguagem natural ao fornecer uma interface de alto nível.\n",
        "\n",
        "Parâmetros:\n",
        "* `model`: Modelo de linguagem a ser usado (definido por model_id).\n",
        "\n",
        "* `tokenizer`: Tokenizador correspondente ao modelo para processar o texto.\n",
        "\n",
        "* `task`: Tipo de tarefa (ex.: \"text-generation\" para geração de texto).\n",
        "\n",
        "* `temperature`: Controla a aleatoriedade (lembre-se de variar o valor, conforme as dicas que passamos).\n",
        "\n",
        "* `max_new_tokens`: Número máximo de tokens gerados na saída.\n",
        "\n",
        "* `do_sample`: Habilita/desabilita amostragem estocástica (geração não determinística).\n",
        "\n",
        "* `repetition_penalty`: Penaliza repetições (valores >1 reduzem repetições).\n",
        "\n",
        "* `return_full_text`: Se False, retorna apenas o texto gerado (ignorando o prompt)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavS7aMDDHun"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    task = \"text-generation\",\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 500,\n",
        "    do_sample = True,\n",
        "    repetition_penalty = 1.1,\n",
        "    return_full_text = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ro2IoPx_Kmk"
      },
      "source": [
        "Para carregar a LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szMtJKHNDq0u"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline = pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmBFPoChDuw_"
      },
      "outputs": [],
      "source": [
        "input = \"Gere um texto sobre alimentação saudável, em 1 parágrafo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzezSQB_Lv1"
      },
      "source": [
        "**Geração do resultado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr_hZJQqDx72"
      },
      "outputs": [],
      "source": [
        "output = llm.invoke(input)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sltBUQfM_NgX"
      },
      "source": [
        "**Adequando o prompt com Templates (quando necessário)**\n",
        "\n",
        "Talvez o resultado acima ficou um pouco estranho, ou ele inventou algum texto antes de fornecer o resultado.\n",
        "Para evitar alucinações ou geração infinita de texto, use o template oficial do modelo Phi 3, que inclui tokens especiais como:\n",
        "\n",
        "* <|system|>, <|user|>, <|assistant|>: definem os papéis da mensagem.\n",
        "\n",
        "* <|end|>: marca o fim do texto (equivalente ao token EOS).\n",
        "\n",
        "Na dúvida, acesse a página do modelo no Hugging Face, se houver um template recomendável para o modelo ele estará na descrição.\n",
        "\n",
        "Para outras implementações pode não ser necessário fornecer o prompt, como por exemplo a implementação via API que usamos anteriormente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yykLahTtEGTj"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "<|system|>\n",
        "Você é um especialista em marketing digital com foco em SEO e escrita persuasiva.<|end|>\n",
        "<|user|>\n",
        "\"{}\"<|end|>\n",
        "<|assistant|>\n",
        "\"\"\".format(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fynuo2s3EVAD"
      },
      "outputs": [],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex-45atXEY8R"
      },
      "outputs": [],
      "source": [
        "output = llm.invoke(prompt)\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k4NXTtU_Quq"
      },
      "source": [
        "* Considerações finais: A vantagem de usarmos o LangChain é que toda a sintaxe e lógca que criamos para esse projeto (por exemplo chains) é reaproveitada, o que muda é a parte de carregar a llm, o resto pode permanecer igual. Então, bastaria substituir o método de carregamento da LLM do LangChain (por exemplo, ao invés de ChatGroq usar o HuggingFacePipeline ou o ChatHuggingFace) e com isso você teria a aplicação funcionando o mesmo modo, porém rodando tudo localmente (seja cloud ou no computador local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYTnwIbn_R5l"
      },
      "source": [
        "### -> Para rodar em seu computador\n",
        "\n",
        "Para usar a LLM localmente via API: use o mesmo código desse Colab, fazendo a instalação das bibliotecas instaladas (no comando de instalação, ao início desse Colab).\n",
        "\n",
        "Para usar a LLM baixando o modelo localmente:\n",
        "Para maior compatibilidade de execução de LLMs em máquina local nós sugerimos a biblioteca [Ollama](https://ollama.com), que possui integração direta com o LangChain.\n",
        "\n",
        "* Rode o arquivo llm_local.py e instale todas as bibliotecas necessárias conforme consta nos comentários ao início do .py\n",
        "\n",
        "Recomendamos usar pelo Colab pelo menos no início e para não atrapalhar o fluxo de aprendizado deste curso. Ao executar localmente podem ocorrer outros problemas de instalação ou incompatibilidade, e de início pode perder tempo desnecessário. O método que mostraremos tenta evitar esses tipos de erro mas ainda assim é impossível garantir 100%, portanto sugerimos primeiro testar pelo Colab e depois (se quiser) executar em sua máquina local.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4341db4ded8443288d701b9be22c436f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Tema:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6a98d6322c6945e6bc341cbad9abb014",
            "placeholder": "Ex: saúde mental, alimentação saudável, prevenção, etc.",
            "style": "IPY_MODEL_1d1bcd9dd7224bccbe574f134f90bb72",
            "value": ""
          }
        },
        "6a98d6322c6945e6bc341cbad9abb014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1bcd9dd7224bccbe574f134f90bb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e36a5f82874bfcbad64d900666e321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Tema:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f0304498b77c4e9eb71516cb328f4bf6",
            "placeholder": "Ex: saúde mental, alimentação saudável, prevenção, etc.",
            "style": "IPY_MODEL_129c8443633b49fd94e7913c9734ada4",
            "value": ""
          }
        },
        "f0304498b77c4e9eb71516cb328f4bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "500px"
          }
        },
        "129c8443633b49fd94e7913c9734ada4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2bdab56ce824ca9b908fae804ab7425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Instagram",
              "Facebook",
              "LinkedIn",
              "Blog",
              "E-mail"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Plataforma",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_0299e82c52304d8ca88cf41c50d4eed5",
            "style": "IPY_MODEL_e3c621de95624683a77b4c80f86212e6"
          }
        },
        "0299e82c52304d8ca88cf41c50d4eed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "e3c621de95624683a77b4c80f86212e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b69ba16998b24b95943171e9e07dbee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Normal",
              "Informativo",
              "Inspirador",
              "Urgente",
              "Informal"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Tom:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_0a9c2ec91404485db7a7b0a812e11b16",
            "style": "IPY_MODEL_0ee1ecf9e84d4eb2b6da834c753feaa8"
          }
        },
        "0a9c2ec91404485db7a7b0a812e11b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "0ee1ecf9e84d4eb2b6da834c753feaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c8890cd00a44c29987fb02bfade45f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Curto",
              "Médio",
              "Longo"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Tamanho:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_23b14597e67b4af3a89f56afd424565d",
            "style": "IPY_MODEL_34fff4152d54492c974ba0e3117e792e"
          }
        },
        "23b14597e67b4af3a89f56afd424565d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "34fff4152d54492c974ba0e3117e792e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb2156884344740a342a0a51f91787a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Geral",
              "Jovens adultos",
              "Famílias",
              "Idosos",
              "Adolescentes"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Público-alvo:",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_271de9033b78475cb8bbfded02cac237",
            "style": "IPY_MODEL_cc1d9c4773e44f3b92649b8d5d256c0d"
          }
        },
        "271de9033b78475cb8bbfded02cac237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "cc1d9c4773e44f3b92649b8d5d256c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "300a1da0f87d4c20930b8236cb921313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Incluir CTA",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b1429d3fc8d249beb273cb64ecf2acf5",
            "style": "IPY_MODEL_5056d268d76d4d3499273dc378a50e0d",
            "value": false
          }
        },
        "b1429d3fc8d249beb273cb64ecf2acf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5056d268d76d4d3499273dc378a50e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a60140076ead460c8c0e0bc3311eeeba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Palavras-chave (SEO)",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7aa393414c6948c5b164d2b9f09eb21c",
            "placeholder": "Ex: bem-estar, medicina preventiva...",
            "rows": null,
            "style": "IPY_MODEL_5f7751ccecc245789af2a84301bc3a21",
            "value": ""
          }
        },
        "7aa393414c6948c5b164d2b9f09eb21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "500px"
          }
        },
        "5f7751ccecc245789af2a84301bc3a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94212f66ad5748e09a47f257c4f54afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Gerar conteúdo",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bb519a8ea337412a8eb4d5382266552a",
            "style": "IPY_MODEL_3e6f46a0afac4de8bf4419a0b0a0ddb6",
            "tooltip": ""
          }
        },
        "bb519a8ea337412a8eb4d5382266552a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6f46a0afac4de8bf4419a0b0a0ddb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "019ed3585d9346128b8830ab024d2949": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e9b2689633f04d478b50e8245be2c121",
            "msg_id": "",
            "outputs": []
          }
        },
        "e9b2689633f04d478b50e8245be2c121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad8acbaf16b42359c56f0b9e65135db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e36a5f82874bfcbad64d900666e321",
              "IPY_MODEL_e2bdab56ce824ca9b908fae804ab7425",
              "IPY_MODEL_b69ba16998b24b95943171e9e07dbee2",
              "IPY_MODEL_9c8890cd00a44c29987fb02bfade45f8",
              "IPY_MODEL_0fb2156884344740a342a0a51f91787a",
              "IPY_MODEL_300a1da0f87d4c20930b8236cb921313",
              "IPY_MODEL_27ba1b96670c409eaed4d6e37b1263da",
              "IPY_MODEL_a60140076ead460c8c0e0bc3311eeeba",
              "IPY_MODEL_94212f66ad5748e09a47f257c4f54afc",
              "IPY_MODEL_019ed3585d9346128b8830ab024d2949"
            ],
            "layout": "IPY_MODEL_fe940e1f861342bfa398cc04d779b83a"
          }
        },
        "27ba1b96670c409eaed4d6e37b1263da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Retornar Hashtags",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d39913c90fe04fca8d19bd4915b8db82",
            "style": "IPY_MODEL_ed24be2c4aec43f889017ec3aab86a50",
            "value": false
          }
        },
        "fe940e1f861342bfa398cc04d779b83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39913c90fe04fca8d19bd4915b8db82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed24be2c4aec43f889017ec3aab86a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96234e8cf1644f379c82137a3349e6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e36a5f82874bfcbad64d900666e321",
              "IPY_MODEL_e2bdab56ce824ca9b908fae804ab7425",
              "IPY_MODEL_b69ba16998b24b95943171e9e07dbee2",
              "IPY_MODEL_9c8890cd00a44c29987fb02bfade45f8",
              "IPY_MODEL_0fb2156884344740a342a0a51f91787a",
              "IPY_MODEL_300a1da0f87d4c20930b8236cb921313",
              "IPY_MODEL_27ba1b96670c409eaed4d6e37b1263da",
              "IPY_MODEL_a60140076ead460c8c0e0bc3311eeeba",
              "IPY_MODEL_94212f66ad5748e09a47f257c4f54afc",
              "IPY_MODEL_019ed3585d9346128b8830ab024d2949"
            ],
            "layout": "IPY_MODEL_f258888580da46e7aed44538602a9e13"
          }
        },
        "f258888580da46e7aed44538602a9e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d2b18b2d7a4c159732d64e04caa01a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e36a5f82874bfcbad64d900666e321",
              "IPY_MODEL_e2bdab56ce824ca9b908fae804ab7425",
              "IPY_MODEL_b69ba16998b24b95943171e9e07dbee2",
              "IPY_MODEL_9c8890cd00a44c29987fb02bfade45f8",
              "IPY_MODEL_0fb2156884344740a342a0a51f91787a",
              "IPY_MODEL_300a1da0f87d4c20930b8236cb921313",
              "IPY_MODEL_27ba1b96670c409eaed4d6e37b1263da",
              "IPY_MODEL_a60140076ead460c8c0e0bc3311eeeba",
              "IPY_MODEL_974efff07f8d48e5aa09830ab30df83a",
              "IPY_MODEL_19ea002d58844c5c900558c5c559f691"
            ],
            "layout": "IPY_MODEL_c4106067fbe347508f84f40ccfe88a53"
          }
        },
        "974efff07f8d48e5aa09830ab30df83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Gerar conteúdo",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_6c1f5313ebce4feeae0def861333595e",
            "style": "IPY_MODEL_ce644390b53043459b15c5bedafadac9",
            "tooltip": ""
          }
        },
        "19ea002d58844c5c900558c5c559f691": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7c04dd45c27446ceb1a68a6f04ecc37b",
            "msg_id": "",
            "outputs": []
          }
        },
        "c4106067fbe347508f84f40ccfe88a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1f5313ebce4feeae0def861333595e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce644390b53043459b15c5bedafadac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7c04dd45c27446ceb1a68a6f04ecc37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3c6b686b2e455581ae242aa9e8e4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e36a5f82874bfcbad64d900666e321",
              "IPY_MODEL_e2bdab56ce824ca9b908fae804ab7425",
              "IPY_MODEL_b69ba16998b24b95943171e9e07dbee2",
              "IPY_MODEL_0f6ca7d0a9344f1388fee1bf76039d96",
              "IPY_MODEL_0fb2156884344740a342a0a51f91787a",
              "IPY_MODEL_300a1da0f87d4c20930b8236cb921313",
              "IPY_MODEL_27ba1b96670c409eaed4d6e37b1263da",
              "IPY_MODEL_a60140076ead460c8c0e0bc3311eeeba",
              "IPY_MODEL_974efff07f8d48e5aa09830ab30df83a",
              "IPY_MODEL_19ea002d58844c5c900558c5c559f691"
            ],
            "layout": "IPY_MODEL_3d47f5cd828c40b892f5724333c9a806"
          }
        },
        "0f6ca7d0a9344f1388fee1bf76039d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "C",
              "u",
              "r",
              "t",
              "o",
              ",",
              " ",
              "M",
              "é",
              "d",
              "i",
              "o",
              ",",
              " ",
              "L",
              "o",
              "n",
              "g",
              "o",
              ",",
              " ",
              "1",
              " ",
              "p",
              "a",
              "r",
              "á",
              "g",
              "r",
              "a",
              "f",
              "o",
              ",",
              " ",
              "1",
              " ",
              "p",
              "á",
              "g",
              "i",
              "n",
              "a"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Tamanho",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_75b1c58cbe8a461db6fbd40ccdcb8456",
            "style": "IPY_MODEL_f7d3c33e0bfa4628ad97c7b526921a0c"
          }
        },
        "3d47f5cd828c40b892f5724333c9a806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b1c58cbe8a461db6fbd40ccdcb8456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "250px"
          }
        },
        "f7d3c33e0bfa4628ad97c7b526921a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}